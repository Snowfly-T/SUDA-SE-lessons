# 课程作业

包含本课程全部作业题目，且包含个人解答（代码+实验报告）。

这门课是按照最终交的几个项目作业评分的，有点抽象，我具体来讲一讲是怎么回事。

首先由于这门课只开了三年，所以一切都处于摸索阶段，谁也不知道接下来会不会变，一切仅供参考。前两年是按照个人为单位进行项目开发的，我上的这年变成了以团队为单位，9人一组，全班分三组，一起完成3个项目。我也不知道下一年会不会又改回单人。

对这三个项目的详细解释如下：

1. **二维码扫描签到系统**：开发一个Web项目，可以打开一个页面，展示一些用于上课签到的二维码，下面的同学通过微信/企业微信扫码签到。需要有数据库保存签到记录，进行查看统计等。每个二维码扫描签到完成后需要展示学生的头像和姓名，并在几秒后刷新，让下一个同学来签到。
2. **大数据检索速度竞赛**：在2组5亿条（每个20G以上）数据记录中，找出相同（相似）的数据集合。可以使用各种软件和方法，寻找更可靠的解决方案，以速度快方法优秀作为考核条件，尤其是可以在数据继续扩展的情况下的解决方案为优。
3. **大学校园家教设计与调研**：参与设计调研和学校学生有关的信息化平台。编写调研报告。关于大学生家教的平台设计，学生需求，薪资水平，家长需求痛点，以及相应的技术准备，运营思路，产品包装设计，广告设计等。从学校学生角度调研产品需求，从已经有家教经验的学生收集汇总经验，从客户角度分析产品设计，薪酬设计，尽可能学会在一个较高的高度看待产品理解产品，学习开发产品而准备一个设计者的高度。这东西其实只要做个PPT，然后有人演讲就行，不需要实现的。

顺便实验报告中的描述是老师给的，上面有些小错误，比如这次是按组为单位开发，不是每个人都要提交一份的。

## 二维码扫描签到系统

我详细说说这三个项目。首先第一个签到系统，本质上就是一个标准的Web项目，不管是用JSP那种、Spring Boot+模板引擎、前后端分离，都是可以的，只要能实现就行了。大家都是找已有的后台管理框架来写的。老师给了一个Java Guns框架，其他两个小组都用了这个框架，是个前后端不分离的框架，就是Spring Boot+模板引擎那一套逻辑。我自己带的小组另外找了个前后端分离的开源框架[web-flash](http://webflash.enilu.cn/)，主要是觉得2022年还不做前后端分离有点太落后了。说实话再让我选的话我也许会考虑个看起来更美好的框架叫[BallCat](http://www.ballcat.cn/)，技术更新，看着更好看，Vue 3和React版本的前端都有，但我没有实际用过，不做评论，我建议后来的同学可以考虑试试。

签到系统这块主要难点其实不是展示二维码、连接数据库这些，这些东西都是很简单的。主要难点在于如何对接企业微信。企业微信那边对接起来还是挺麻烦的，各种身份认证搞一堆。我们小组最终是部署到自己的服务器上并且按照企业微信那边的官方文档做了OAuth2的鉴权，如果没有服务器需要本地搞的话就更加麻烦了。具体的代码已经放在目录下了，后端就是个标准的Spring Boot+Spring Data JPA+Shiro+Springfox后端，注意没用MyBatis而是用的Spring Data JPA，这主要是我个人的喜好问题；前端是拿Vue Element Admin改的，就是个Vue 2+Element UI的实现，整体技术说实话还是偏老了，现在再叫我写的话我会考虑用Vue 3+Element Plus或React+MUI/AntD。

然后具体来说，签到系统还是团队共同实现的一个项目，除我以外团队里有6人参与，我分成三个前端三个后端。我每周日晚上会线上开个会把大家集中一下讨论一下本周的进展和问题，并制定下一周的计划。其实说实在的我个人写的代码不多，我就是开了个头，大部分代码是大家一起写的。具体相关说明我已经放在代码文件夹的`README.md`和实验报告里了，自己去看吧。

## 大数据检索速度竞赛

然后是大数据竞赛，这个就是在两组随机生成的数据里，找出相似的数据。具体来说，需要运行代码目录下的`IMSIGenerator.java`，生成两组数据（每组20G左右）。每个数据都是这样的格式：`随机数1|随机数2|随机数3`。你需要找出两组数据中，每一行三个随机数之和相等的数，最终只需要输出两组数据中重复的和就可以了。

### 方法1 Spark

说是大数据，其实这个数据量还挺小的。思路也比较简单，一种是最简单粗暴的思路，拿Spark直接写，核心代码十行以内就解决问题了，Spark既可以用Scala写，也可以用Python，也可以直接写SQL，我有个用Scala写的Spark代码，在`代码（Spark）`文件夹下，可以参考一下。其实文件夹下面还有Python代码，也是一个意思，但是那个我测试下来没法在这么大的数据集上跑，只有Scala写得能跑，我估计实际上是配置的问题，不是说真的不能跑。

Spark这个思路我用Scala写下来最后花了大概三四十分钟能跑完。核心代码真的非常短，我都能直接列在这里：

```scala
val schema = StructType(List(
    StructField("c1", LongType, nullable = false),
    StructField("c2", LongType, nullable = false),
    StructField("c3", LongType, nullable = false)
  ))
val df = spark.read.schema(schema).option("delimiter", "|").csv(paths *)

val window = Window.partitionBy("sum")
val result = df
  .withColumn("sum", col("c1") + col("c2") + col("c3"))
  .withColumn("dupeCount", count("*").over(window))
  .where(col("dupeCount") > 1)
  .drop("dupeCount")
  .sort(col("sum"))
  .collect()
```

其中最核心的代码就是最后那点链式调用，是真的很简单……只要你会Spark，做起来很轻松。

顺便生成数据的那个`IMSIGenerator.java`文件我用Scala也改写了一遍，也在相应的目录下。生成数据时可以不用跑那个Java代码了，直接跑Scala就行了。

然后Scala版本是Scala 3，注意别用Scala 2。Spark无脑下最新版就行了。具体配置不详述了。

具体跑的话我建议用IDEA直接运行`SparkSolution.scala`就行。不要用命令行，我不知道为啥用命令行是跑不完的……

然后那边目录下还有个`IoDivisionSolution.scala`，这东西其实已经没用了，这就是个小尝试，试图用另一种方法解决问题，但运行起来速度不是很理想，看看也行。

### 方法2 分而治之

上面那个Spark版本需要三四十分钟，速度其实不是很理想，后面就尝试了另一个思路。

说起来也很简单，就是将这些文件分块。首先两个数据集加起来四十多个G是没法全部读进内存的，那就分成小块读进内存处理。这分为两步，我称为Cache阶段和Find阶段。

在Cache阶段，先依次读取每一个原始数据，把每一行三个数的和保存到磁盘上的缓存文件中。这一步是分块的，假设这里三个数的和在60000~120000之间，那么就差不多可以分成60块，每块是1000，就是像这样创建多个分块的文件，将三个随机数的和在不同范围内的数字保存到对应的块中，例如60000.txt保存在60000~61000之间的和，61000.txt保存在61000~62000之间的和，以此类推。

在Find阶段，对比两个数据集的缓存文件。显然，重复数据只有可能在对应的块中找到，比如一次读入A数据集的60000.txt和B数据集的60000.txt，在60000~61000这个范围内的重复和只有可能在这两个文件中找到。这样就解决了没法一次在内存中读入所有数据的问题。接下来就很简单了，对每一组对应的块查找重复数据，最后输出就可以了。

这里使用Kotlin编写的代码，其实用什么语言都无所谓，用Kotlin主要是图省事，而且它有协程，写起来可以比较好地利用多核性能。代码放在`代码`文件夹下。顺便生成数据的那个`IMSIGenerator.java`文件我用Kotlin也改写了一遍，也在相应的目录下。生成数据时可以不用跑那个Java代码了，直接跑Kotlin就行了。

运行方式也很简单，用IDEA打开项目，先运行`IMSIGenerator.kt`生成树，然后运行`IoDivisionSolution.kt`就行。最终结果会输出在data/result.txt里。代码不长，一百多行，逻辑也挺清楚，应该很好懂的。

我认为如果愿意的话，用Go或者C++改写应该会稍微快一点，但我没试过，也不敢肯定。

最后跑下来实际上只要400多秒（在我的游戏本上）。但这个思路有个问题，就是磁盘读写非常多，必须要用固态硬盘，用机械硬盘要跑好几天才能出结果，非常慢。

## 大学校园家教设计与调研

这个就看各组收集信息、设计系统的能力了，其实没啥好说的。实际上我们小组做得是最烂的，就是收集了几份问卷然后做了下分析，简单设计了一下平台规范就结束了。做的好点的话像是运营、投放、推广之类的东西都要写上去的。
